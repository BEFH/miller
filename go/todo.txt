----------------------------------------------------------------
TOP OF LIST:

* check all struct-initializers to make sure they're all using colon syntax

* reg_test/run iterate

* neaten/error-proof:
  o mlrmapEntry -> own keys/mlrvals -- keep the kcopy/vcopy & be very clear,
    or remove. (keeping pointers allows nil-check which is good.)
  o inrec *lib.Lrec is good for default no-copy across channels ... needs
    a big red flag though for things like the repeat verb (maybe *only* that one ...)

* array/map
  o map literals & index-accessing
  o err-return for array/map get/put if incorrect types
  o printreps for array/map
  ! defer maps until ordered-map impl
  o mlrval Go Copy method and DSL copy function ... or, better, pass by
    reference throughout RHS but always copy on assignment. (don't
    want references to $* trashing the UX.)

* SUMMARY:
  o easy: most verbs
  o easy: full cli
  o easy: readers/writers including TSV/ASV, and CSV heterogeneity
  o medium: sort/stats1/join
  o will take time: array/map mlrval
  o will take time: full DSL including functions, mapvals, etc

* widen verb coverage
  o label
  o rename
  o group-by
  o cut
  o count
  o repeat
  o head/tail
  o sort
  o filter
  o focus on calendar/DST/TZ improvements

* widen CLI coverage
  o --c2x et al.
  o implement mlrrc

* widen reader coverage
  o TSV/ASV
  o XTAB

â€¢ widen writer coverage
  o TSV/ASV
  o markdown

* I/O
  o --allow-ragged-csv-input|--ragged
  o --implicit-csv-header
  o --headerless-csv-output
  o new non-lite DKVP reader/writer

* widen DSL coverage
  o begin/end blocks
  o indirect field names, at LHS and RHS
  o support the filter verb

* array/map mlrval:
  k srecs as string -> mlrvals
  o add MT_ARRAY and MT_MAP to mlrval
  o support full JSON read/write of nested objects
    - only requirement is that top-level be sequence of string-valued objects ...
    - JSON-to-JSON cat-mapping should be identical
    - JSON-like accessor syntax in the grammar: $field.foo[3].bar{"bar"}
  o implement json.Unmarshaler and json.Marshaler directly for Mlrval
  o implement json.Unmarshaler and json.Marshaler directly for Lrec
  i type Unmarshaler interface { UnmarshalJSON([]byte) error }
  i type Marshaler   interface { MarshalJSON() ([]byte, error) }
  o flatten/unflatten for non-JSON I/O formats -- maybe just double-quoted JSON strings -- ?

----------------------------------------------------------------
MAYBE:

* string index/slice access
* string/array slices on assignment LHS -- ?

----------------------------------------------------------------
GOCC UPSTREAMS:

* support "abc" (not just 'a' 'b' 'c') in the lexer part
* research customization of error-handling ... line numbers in particular ...

----------------------------------------------------------------
DEV NOTES:

* build-dsl
* build
* fmter
* check
* git diff to see what changed
* commit

----------------------------------------------------------------
NITS:

* "...\"..." into string-literal parsing ...
* address all manner of xxx and TODO comments
* support whitespace-only DSL strings (as NOPs), either in the parser or outside ...
* AST insertions: make a simple NodeFromToken & have all interface{} be *ASTNode, not *token.Token
* mlr --help-for w/ stdout redirect for manpage -- ?
* mlr verb -h -> stdout & exit 0
* cst printer with reflect.TypeOf -- ?
* godoc ...
* mlrdoc false && 4, true || 4 because of short-circuiting requirement
* update whyc.html with efficiency notes from go/README.md
? makefile for build-dsl: if $bnf newer than productionstable.go
* I/O perf delta between C & Go is smaller for CSV, middle for DKVP, large for JSON -- debug
